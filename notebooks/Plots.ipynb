{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Entrance Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from plothelpers import Params, extract_params, split_into_runs, entropy\n",
    "import hmp\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, kpss, adfuller\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.vector_ar import plotting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.collections import PolyCollection\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to read the results from\n",
    "proposed_folder = \"../out/general/\"\n",
    "comparison_folder = \"../out/comp/\"\n",
    "noise_folder = \"../out/noise/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(preds, real):\n",
    "    # Note: sklearn has flipped params (real first)\n",
    "    return mean_absolute_error(real, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to c\n",
    "Visualise methods over entire range of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_outputs(path, compression=None):\n",
    "    \n",
    "    all_results = {}\n",
    "\n",
    "    for file_name in glob.glob(path):\n",
    "        runs = pd.read_csv(file_name, index_col=0, compression=compression)\n",
    "        params = extract_params(file_name) # Based on filename\n",
    "        \n",
    "        results = {\n",
    "            \"mean\": runs.mean(axis=1),\n",
    "            \"std\": runs.std(axis=1),  \n",
    "            \"all\": runs,\n",
    "        }\n",
    "        \n",
    "        all_results[params] = results\n",
    "        \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_results = read_outputs(proposed_folder + \"attendance-*\")\n",
    "comparison_results = read_outputs(comparison_folder + \"attendance-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistics(attendance_rates):\n",
    "    cs = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    \n",
    "    for params, results in sorted(attendance_rates.items(), key=lambda x: x[0].c):\n",
    "        means.append(results[\"mean\"].mean())\n",
    "        stds.append(results[\"mean\"].std())\n",
    "        cs.append(params.c)\n",
    "        \n",
    "    return np.asarray(means), np.asarray(stds), np.asarray(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(means, stds, cs, color, label):\n",
    "    plt.plot(cs, means, c=color, label=label)\n",
    "    plt.fill_between(cs, means + stds, means - stds, color=color, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proposed_mean, proposed_std, proposed_cs = summary_statistics(proposed_results)\n",
    "comparison_mean, comparison_std, comparison_cs = summary_statistics(comparison_results)\n",
    "\n",
    "plot_summary(proposed_mean, proposed_std, proposed_cs, color=\"purple\", label=\"BRATS\")\n",
    "plot_summary(comparison_mean, comparison_std, comparison_cs, color=\"orange\", label=\"AS\")\n",
    "    \n",
    "plt.plot([0,1], [0,1], linestyle=\"--\",c=\"red\", label=\"Perfect Utilisation\")\n",
    "plt.xlabel(\"Desirable Entrance Rate\")\n",
    "plt.ylabel(\"Resulting Entrance Rate\")\n",
    "plt.legend()\n",
    "plt.savefig(\"images/attendance.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource Efficiency\n",
    "Visualise the attendance rates for each value of c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(results, params, ax=None, color=None, label=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    T = len(results[\"mean\"])\n",
    "    ts = range(T)\n",
    "    \n",
    "    ax.plot(results[\"mean\"], label=label, c=color, alpha=0.5)\n",
    "    \n",
    "    ax.fill_between(ts, results[\"mean\"] + results[\"std\"], results[\"mean\"] - results[\"std\"],\n",
    "                     color=color, alpha=0.1)\n",
    "    \n",
    "    # Add yticks at c\n",
    "    yticks = [0, params.c, 1]\n",
    "\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([str(int(tick * 100)) + \"%\" for tick in yticks])\n",
    "\n",
    "    ax.grid(None)\n",
    "    ax.set_ylim((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_statistics(runs, goal):\n",
    "    losses = [loss(runs[run], goal) for run in runs]\n",
    "    return {\"mean\": np.mean(losses), \"std\": np.std(losses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(proposed, comparison):\n",
    "    errors = defaultdict(dict)\n",
    "\n",
    "    for param, proposed_result in sorted(proposed.items(), key=lambda x: x[0].c):\n",
    "        \n",
    "        if param not in comparison:\n",
    "            continue\n",
    "            \n",
    "        comparison_result = comparison[param]\n",
    "        goal = [param.c] * len(proposed_result[\"mean\"])\n",
    "                \n",
    "        errors[\"proposed\"][param.c] = loss_statistics(proposed_result[\"all\"], goal)\n",
    "        errors[\"comparison\"][param.c] = loss_statistics(comparison_result[\"all\"], goal)\n",
    "            \n",
    "        # Only plot main points\n",
    "        if (param.c * 100) % 10 == 0:\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4), sharey=True)\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            line(proposed_result, param, ax1, label=\"BRATS\", color=\"purple\")\n",
    "            line(comparison_result, param, ax2, label=\"AS\", color=\"orange\")\n",
    "            \n",
    "            # Add the target line\n",
    "            ax1.axhline(param.c, ls=\"--\", color=\"red\")\n",
    "            ax2.axhline(param.c, ls=\"--\", label=\"Perfect Utilisation\", color=\"red\")\n",
    "            \n",
    "            # Only do legend on 1 plot\n",
    "            if param.c == 0.1:\n",
    "                lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes]\n",
    "                lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "                ax2.legend(lines, labels)\n",
    "\n",
    "            plt.savefig(f\"images/attendance/{param.c}.pdf\", bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = compare(proposed_results, comparison_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors(errors, color, label):\n",
    "    cs = []\n",
    "    means = []\n",
    "    stds = []\n",
    "    for c in sorted(errors):\n",
    "        # Skip cases where everyone goes or nobody goes\n",
    "        if c == 0 or c == 1:\n",
    "            continue\n",
    "\n",
    "        cs.append(c)\n",
    "\n",
    "        means.append(errors[c][\"mean\"])\n",
    "        stds.append(errors[c][\"std\"])\n",
    "        \n",
    "    means = np.asarray(means)\n",
    "    stds = np.asarray(stds)\n",
    "\n",
    "    plt.plot(cs, means,  c=color, label=label)\n",
    "    plt.fill_between(cs, means - stds, means + stds,  color=color, label=label, alpha=0.1)\n",
    "    \n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = plot_errors(errors[\"proposed\"], color=\"purple\", label=\"Proposed\")\n",
    "plot_errors(errors[\"comparison\"], color=\"orange\", label=\"Comparison\")\n",
    "\n",
    "plt.plot(cs, [0] * len(cs), c=\"red\", ls=\"--\", label=\"Optimal\")\n",
    "    \n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.xlabel(\"Desirable Entracy Rate\")\n",
    "plt.savefig(\"images/errors.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustered Volatility\n",
    "Compute temporal autocorrelation functions to examine if clustered volatility is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_change(x):\n",
    "    \"\"\"\n",
    "        A verison of where percentage change where we deal with case of 0 attendance\n",
    "    \"\"\"\n",
    "    # Take a copy since modifying series\n",
    "    x = x.copy()\n",
    "    \n",
    "    # Since we use pct_change, want to avoid case of 0 attendance, treat as attendance of 1%\n",
    "    x += 0.01\n",
    "    \n",
    "    # Compute change\n",
    "    pct_change = x.pct_change()\n",
    "        \n",
    "    if np.any(~np.isfinite(pct_change[1:])):\n",
    "        print(\"Warning, infinite pct_change\")\n",
    "        pct_change[~np.isfinite(pct_change)] = 0\n",
    "    \n",
    "    # Exception is first one, which we should just treat as 0 since no change\n",
    "    pct_change[0] = 0\n",
    "    \n",
    "    return pct_change \n",
    "\n",
    "def volatility(x):\n",
    "    return pct_change(x).abs() # Measured as absolute percentage change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatility_correlations(runs, c):\n",
    "    correlations = []\n",
    "    confidence_intervals = []\n",
    "\n",
    "    # Compute for each run\n",
    "    for run_col in runs:\n",
    "\n",
    "        run = runs[run_col]\n",
    "        \n",
    "        # Compute volatility for the run -- skip first one since always 0\n",
    "        timeseries = volatility(run)\n",
    "\n",
    "        # Compute autocorrelation with 95% confidence interval\n",
    "        corr, confint = acf(timeseries, nlags=n_lags, alpha=0.05, fft=False,)\n",
    "        \n",
    "        correlations.append(corr)\n",
    "        confidence_intervals.append(confint)\n",
    "        \n",
    "\n",
    "    # Median over each run\n",
    "    return np.median(correlations, axis=0), np.median(confidence_intervals, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_volatility_correlations(filename, mean_correction=None):\n",
    "    \n",
    "    all_correlations = defaultdict(dict)\n",
    "        \n",
    "    \n",
    "    for file in sorted(glob.glob(filename)):\n",
    "        runs = pd.read_csv(file, index_col=0)\n",
    "        params = extract_params(file) # Based on filename\n",
    "        \n",
    "        if mean_correction:\n",
    "            runs -= mean_correction\n",
    "        \n",
    "        if (params.c == 0 ) or (params.c == 1) or (params.c * 100) % 10 != 0:\n",
    "            continue\n",
    "\n",
    "        correlations, confidence_intervals = volatility_correlations(runs, params.c)\n",
    "        \n",
    "        all_correlations[params.c][\"median\"] = correlations\n",
    "        all_correlations[params.c][\"interval\"] = confidence_intervals\n",
    "        \n",
    "    return all_correlations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "proposed_volatility_correlations = read_volatility_correlations(proposed_folder + \"attendance-*\")\n",
    "comparison_volatility_correlations = read_volatility_correlations(comparison_folder + \"attendance-*\")\n",
    "# Noise traders need to be de-meaned since they will always fluctuate around 0.5\n",
    "noise_volatility_correlations = read_volatility_correlations(noise_folder + \"attendance-*\", mean_correction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "legend = True # Only draw once\n",
    "\n",
    "for c in proposed_volatility_correlations:\n",
    "    \n",
    "    if (c * 100) % 10 != 0:\n",
    "        continue\n",
    "        \n",
    "    correlations = proposed_volatility_correlations[c]\n",
    "    comparison_correlations = comparison_volatility_correlations[c]\n",
    "    random_correlations = noise_volatility_correlations[c]\n",
    "    \n",
    "    # Plot Correlation\n",
    "    plt.plot(correlations[\"median\"], c=\"purple\", label=\"BRATS\")\n",
    "        \n",
    "    # Plot Confidence intervals\n",
    "    plt.fill_between(range(n_lags + 1), correlations[\"interval\"][:, 0] - correlations[\"median\"], correlations[\"interval\"][:, 1] - correlations[\"median\"],\n",
    "                     alpha=0.1, color=\"gray\", zorder=0)\n",
    "    \n",
    "    \n",
    "    if comparison_correlations:\n",
    "        plt.plot(comparison_correlations[\"median\"], c=\"orange\", label=\"AS\")\n",
    "        \n",
    "        # Plot Confidence intervals\n",
    "        plt.fill_between(range(n_lags + 1), comparison_correlations[\"interval\"][:, 0] - comparison_correlations[\"median\"],\n",
    "                         comparison_correlations[\"interval\"][:, 1] - comparison_correlations[\"median\"],\n",
    "                         alpha=0.1, color=\"gray\", zorder=0)\n",
    "\n",
    "    else:\n",
    "        print(\"Warning, no comparison for params\")\n",
    "        \n",
    "    # Plot random for control/comparison\n",
    "    if random_correlations:\n",
    "        plt.plot(random_correlations[\"median\"], linestyle=\"--\", color=\"gray\", label=\"Noise traders\")\n",
    "        \n",
    "            # Plot Confidence intervals\n",
    "        plt.fill_between(range(n_lags + 1), random_correlations[\"interval\"][:, 0] - random_correlations[\"median\"],\n",
    "                         random_correlations[\"interval\"][:, 1] - random_correlations[\"median\"],\n",
    "                         alpha=0.1, color=\"gray\", zorder=0)\n",
    "    else:\n",
    "        print(\"Warning, no random comparison for params\")\n",
    "\n",
    "    \n",
    "    plt.ylabel(\"Correlation\")\n",
    "    plt.xlabel(\"Time Lag\")\n",
    "\n",
    "    if legend:\n",
    "        plt.legend()\n",
    "        legend = False\n",
    "        \n",
    "    plt.savefig(f\"images/clustered_volatility/{c}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endogenous crises\n",
    "Explore the endogenous emergence of crisis, in terms of fat-tails and excess volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurence_probability(raw_values):\n",
    "    combined_dict = {}\n",
    "    \n",
    "    for std_range, values in raw_values.items():\n",
    "        # Combine into one frame\n",
    "        values = np.hstack(values)\n",
    "\n",
    "        # Count percentage of trues\n",
    "        combined_dict[std_range] = 100 * np.sum(values) / len(values)\n",
    "    \n",
    "    return combined_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_event_occurences(filename, verbose=True):\n",
    "    # For counting occurences outside of 1,2,3 stdev\n",
    "    occurences = {}\n",
    "    \n",
    "    for file in sorted(glob.glob(filename)):\n",
    "        runs = pd.read_csv(file, index_col=0)\n",
    "        params = extract_params(file) # Based on filename\n",
    "        \n",
    "        if params.c == 0 or params.c == 1 or (params.c * 100) % 10 != 0:\n",
    "            continue\n",
    "\n",
    "        # Will explore events outside 3 standard deviations\n",
    "        std_range = [3]\n",
    "\n",
    "        outside_range = defaultdict(list)        \n",
    "        \n",
    "        for run in runs:\n",
    "            run = runs[run]\n",
    "                        \n",
    "            # Look at \"returns\"\n",
    "            run = pct_change(run)\n",
    "            \n",
    "            mean, std = run.mean(), run.std()\n",
    "\n",
    "            # Calculate for each of the standard deviation ranges (e.g. 1, 2, 3)\n",
    "            for std_multiplier in std_range:\n",
    "\n",
    "                # See how many fall outside the range\n",
    "                events = np.logical_or(run > (mean + std_multiplier * std), run < (mean - std_multiplier * std))\n",
    "                                \n",
    "                # Track events outside\n",
    "                outside_range[std_multiplier].append(events)\n",
    "                \n",
    "        probabilities = occurence_probability(outside_range)   \n",
    "        \n",
    "        # Store the average occurences\n",
    "        occurences[params.c] = {k: round(v, 1) for (k, v) in probabilities.items()}\n",
    "\n",
    "        if verbose:\n",
    "            print(params, occurences[params.c])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"32, 5, 0.3\")\n",
    "        \n",
    "    return pd.DataFrame(occurences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fat-tails\n",
    "Check the distribution of volatility rates and see if we experience fatter tails than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs(dfs):\n",
    "    \n",
    "    # Combine them all. Add index to end so can display in right order (order passed in)\n",
    "    for idx, df in enumerate(dfs):\n",
    "        df.columns = [f\"{col}_{idx}\" for col in df.columns]\n",
    "\n",
    "    combined_df = pd.concat(dfs, axis=1)\n",
    "    combined_df = combined_df.reindex(sorted(combined_df.columns), axis=1)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extreme_event_occurences = compute_event_occurences(proposed_folder + \"attendance-*\", verbose=False)\n",
    "extreme_event_occurences_comparison = compute_event_occurences(comparison_folder + \"attendance-*\", verbose=False)\n",
    "extreme_event_occurences_noise = compute_event_occurences(noise_folder + \"attendance-*\", verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_dfs([extreme_event_occurences, extreme_event_occurences_comparison, extreme_event_occurences_noise])\n",
    "df.to_csv(\"images/tail-p.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_estimator(returns, tail_size):\n",
    "    # Based on https://www.financialriskforecasting.com/code/MATLABPython9.html\n",
    "    returns = np.abs(returns) # Assume symettric for computing\n",
    "    ysort = np.sort(-returns)   # sort the returns\n",
    "    tail_length = int(len(returns) * tail_size)\n",
    "    alpha = 1/(np.mean(np.log(ysort[0:tail_length]/ysort[tail_length]))) # get the tail index\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_index(runs):\n",
    "    tail_sizes = [0.025, 0.05, 0.1]\n",
    "    tail_estimates = defaultdict(list)\n",
    "\n",
    "    for run in runs:\n",
    "        run = runs[run]\n",
    "\n",
    "        # Look at \"returns\" - i.e., change in attendance\n",
    "        run = pct_change(run)\n",
    "\n",
    "        for tail_size in tail_sizes:\n",
    "            estimate = hill_estimator(run, tail_size=tail_size)\n",
    "            tail_estimates[tail_size].append(estimate)\n",
    "\n",
    "    # Store the average occurences\n",
    "    return {tail_size: round(np.median(estimates), 1) for tail_size, estimates in tail_estimates.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tail_shapes(filename):\n",
    "    # For tail estimates\n",
    "    occurences = {}\n",
    "    \n",
    "    for file in sorted(glob.glob(filename)):\n",
    "        runs = pd.read_csv(file, index_col=0)\n",
    "        params = extract_params(file) # Based on filename\n",
    "        \n",
    "        if params.c == 0 or params.c == 1 or params.c == 1 or (params.c * 100) % 10 != 0:\n",
    "            continue     \n",
    "             \n",
    "        # Store the average occurences\n",
    "        occurences[params.c] = tail_index(runs)\n",
    "                              \n",
    "    return pd.DataFrame(occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_tail_index = compute_tail_shapes(proposed_folder + \"attendance-*\")\n",
    "comparison_tail_index = compute_tail_shapes(comparison_folder + \"attendance-*\")\n",
    "noise_tail_index = compute_tail_shapes(noise_folder + \"attendance-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_dfs([proposed_tail_index, comparison_tail_index, noise_tail_index])\n",
    "df.to_csv(\"images/tail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"BRATS\": proposed_tail_index.values.flatten(),\n",
    "    \"AS\": comparison_tail_index.values.flatten(),\n",
    "    \"Noise Traders\": noise_tail_index.values.flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colours = [\"purple\", \"orange\", \"gray\"]\n",
    "ax = sns.violinplot(data=df, color=\"gray\",)\n",
    "\n",
    "for idx, violin in enumerate(ax.findobj(PolyCollection)):\n",
    "    color = colours[idx]\n",
    "    violin.set_edgecolor(color)\n",
    "    violin.set_facecolor(color)\n",
    "    violin.set_alpha(0.5)\n",
    "    \n",
    "for idx, line in enumerate(ax.get_lines()):\n",
    "    if idx % 2 != 0:\n",
    "        idx = idx -1\n",
    "    color = colours[idx // 2]\n",
    "    line.set_color(color)\n",
    "\n",
    "plt.axhline(1, ls=\"--\", c=\"gray\")\n",
    "plt.axhline(4, ls=\"--\", c=\"gray\")\n",
    "plt.xlabel(\"Method\")\n",
    "plt.ylabel(r\"Tail Index ($\\alpha$)\")\n",
    "\n",
    "plt.savefig(\"images/violin.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underlying causes\n",
    "In this section we look to perform econometric analysis to analyse underlying causes for the stylized facts observed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_timeseries = {}\n",
    "\n",
    "attendance = read_outputs(proposed_folder + \"attendance-*\")\n",
    "for file in glob.glob(proposed_folder + \"resources-*\"):\n",
    "    params = extract_params(file) # Based on filename\n",
    "    \n",
    "    if params.c == 0 or params.c == 1 or (params.c * 100) % 10 != 0:\n",
    "        continue\n",
    "    \n",
    "    results = pd.read_csv(file, index_col=0)\n",
    "    runs = split_into_runs(results, params)\n",
    "\n",
    "    entropies = []\n",
    "    volatilities = []\n",
    "\n",
    "    for run_idx, run in enumerate(runs):\n",
    "        attendance_run = attendance[params][\"all\"][str(run_idx)]\n",
    "\n",
    "        # Differencing in volatility -- as volatility not necessarily stationary\n",
    "        observed_volatility = volatility(attendance_run).diff()[1:]\n",
    "        volatilities.append(observed_volatility)\n",
    "\n",
    "        # Differencing in population entropt \n",
    "        ent = run.apply(entropy)\n",
    "        ent = ent.diff()[2:] # 2, as first one is 0, and second must be skipped because of diff above\n",
    "\n",
    "        entropies.append(ent)\n",
    "\n",
    "\n",
    "    param_timeseries[params] = {\n",
    "        \"attendance\": attendance[params][\"all\"],\n",
    "        \"volatility\":volatilities,\n",
    "        \"entropy\": entropies,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[proposed_folder] = param_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bitstring_to_numeric(bitstring):\n",
    "    # Convert a bit string into its numeric representation\n",
    "    return bitstring.dot(2**np.arange(bitstring.size)[::-1])\n",
    "\n",
    "def comparison_timeseries(path, comparison_attendance):\n",
    "    comparison_param_timeseries = {}\n",
    "\n",
    "    for file in glob.glob(path):\n",
    "        params = extract_params(file) # Based on filename\n",
    "        \n",
    "        if params.c == 0 or params.c == 1 or (params.c * 100) % 10 != 0:\n",
    "            continue\n",
    "\n",
    "        results = pd.read_csv(file, index_col=0, compression=\"gzip\")\n",
    "        all_strategies = split_into_runs(results, params)\n",
    "        \n",
    "        attendance_runs = []\n",
    "        volatilities = []\n",
    "        entropies = []\n",
    "\n",
    "        for run_idx, run in enumerate(all_strategies):\n",
    "\n",
    "            attendance_run = comparison_attendance[params][\"all\"][str(run_idx)]\n",
    "            attendance_runs.append(attendance_run)\n",
    "            \n",
    "            vectors = []\n",
    "            strategy_entropies = []\n",
    "            \n",
    "            for t in run:\n",
    "                time = int(t)\n",
    "\n",
    "                # Best strategy for the previous timestep\n",
    "                strategy_space = run[str(time - 1) if time > 0 else \"0\"]\n",
    "                \n",
    "                # Read each as list, then convert to numpy\n",
    "                strategy_space = np.vstack(strategy_space.apply(lambda x: eval(x)))\n",
    "\n",
    "                # -1 as there is also the bias term\n",
    "                M = strategy_space.shape[1] - 1\n",
    "\n",
    "                # Only do it with enough history\n",
    "                if time >= M:\n",
    "                    history = attendance_run[time - M: time].values\n",
    "                    history = history[::-1] # netlogo treats most recent first, so reverse order\n",
    "                    history = history * params.N # Also convert it back to number\n",
    "                    \n",
    "                    # First col is the bias/constant\n",
    "                    bias = strategy_space[:,0]\n",
    "                    constant = (params.N * bias)\n",
    "                    \n",
    "                    # Rest of strategy as multipliers on history\n",
    "                    weights = strategy_space[:,1:]\n",
    "                    weighted_history = weights * history\n",
    "                    \n",
    "                    # Combine them\n",
    "                    strategy_vector = np.column_stack((weighted_history, constant))\n",
    "                                        \n",
    "                    # Convert to bitstring and compute entropy\n",
    "                    agent_bitstrings = strategy_vector >= 0\n",
    "                    numeric_representations = np.asarray([bitstring_to_numeric(bitstring) for bitstring in agent_bitstrings])\n",
    "                    ent = entropy(numeric_representations)\n",
    "                    strategy_entropies.append(ent)\n",
    "                    \n",
    "            strategy_entropy = pd.Series(strategy_entropies).diff()[1:]\n",
    "            entropies.append(strategy_entropy)\n",
    "\n",
    "            observed_volatility = volatility(attendance_run).diff()[M:]\n",
    "            volatilities.append(observed_volatility)\n",
    "\n",
    "        comparison_param_timeseries[params] = {\n",
    "            \"attendance\": attendance_runs,\n",
    "            \"volatility\":volatilities,\n",
    "            \"entropy\": entropies,\n",
    "        }\n",
    "        \n",
    "    return comparison_param_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_attendance = read_outputs(comparison_folder + \"attendance-*\")\n",
    "comparison_param_timeseries = comparison_timeseries(comparison_folder + \"strategies-*\", comparison_attendance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[comparison_folder] = comparison_param_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check stationarity\n",
    "Before doing anything, we test for stationarity of the data. We check for unit root with Augmented Dickey-Fuller test, then stationary with Kwiatkowski–Phillips–Schmidt–Shin tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationarity_check(timeseries_runs):\n",
    "    # Check unit root\n",
    "    unit_root_p_val = [adfuller(timeseries)[1] for timeseries in timeseries_runs]\n",
    "    # Check stationarity\n",
    "    non_stationarity_p_val = [kpss(timeseries)[1] for timeseries in timeseries_runs]\n",
    "    \n",
    "    # Combine p-values from each of the runs\n",
    "    return {\n",
    "        \"Unit root\":  hmp.hmp(unit_root_p_val),\n",
    "        \"Non-Stationarity\":  hmp.hmp(non_stationarity_p_val),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import InterpolationWarning\n",
    "warnings.simplefilter('ignore', InterpolationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder, timeseries_dict in results.items():\n",
    "    \n",
    "    print(folder)\n",
    "    \n",
    "    for params, result in timeseries_dict.items():\n",
    "        print(\"Entropy:\", stationarity_check(param_timeseries[params][\"entropy\"]))\n",
    "        print(\"Volatility:\", stationarity_check(param_timeseries[params][\"volatility\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine lag-order\n",
    "\n",
    "M appears to be a good option for the lag-order a priori, as this specifies the history length of the agents. Here, we verify that using M as leg lengths is a good option by computing the Akaike information criterion (AIC) for all lags up to 100 -- and show that AIC is minimised at or around M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ranks(param_results):\n",
    "    \n",
    "    param_ranks = {}\n",
    "    \n",
    "    for params, result in param_results.items():\n",
    "    \n",
    "        population_entropies = result[\"entropy\"]\n",
    "        all_lags = []\n",
    "\n",
    "        for run_idx, population_entropy in enumerate(population_entropies):\n",
    "\n",
    "            observed_volatility = result[\"volatility\"][run_idx]\n",
    "\n",
    "            df = pd.DataFrame({\"vol\": list(observed_volatility), \"ent\": population_entropy})\n",
    "            df.index = pd.RangeIndex(start=0, stop=len(population_entropy))\n",
    "\n",
    "            model = VAR(df)\n",
    "\n",
    "            # Select appropriate lags\n",
    "            selections = model.select_order(maxlags=100)\n",
    "            aics = selections.ics[\"aic\"] # Information criteria for each lag\n",
    "            lag_ranks = pd.Series(aics).rank() # rank 1 = lowest AIC\n",
    "            all_lags.append(lag_ranks)\n",
    "\n",
    "        param_ranks[params] = np.asarray(all_lags)\n",
    "        \n",
    "    return param_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_rankings = compute_ranks(results[proposed_folder])\n",
    "comparison_param_rankings = compute_ranks(results[comparison_folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ranks(lag_ranks, color):\n",
    "    lag_ranks = np.asarray(lag_ranks)\n",
    "    q1_rank, median_rank, q3_rank = np.percentile(lag_ranks, q=[25,50, 75], axis=0)\n",
    "\n",
    "    plt.plot(median_rank, color=color)\n",
    "    plt.fill_between(range(len(median_rank)), q1_rank, q3_rank, alpha=0.2, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params, lag_ranks in param_rankings.items():\n",
    "    \n",
    "    comparison_lag_ranks = comparison_param_rankings[params]\n",
    "    \n",
    "    plot_ranks(lag_ranks, color=\"purple\")\n",
    "    plot_ranks(comparison_lag_ranks, color=\"orange\")\n",
    "    \n",
    "    plt.xlabel(\"Lags\")\n",
    "    plt.ylabel(\"AIC Rank\")\n",
    "    plt.savefig(f\"images/lags/{params.c}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lag_order = {\n",
    "    proposed_folder: {},\n",
    "    comparison_folder: {},\n",
    "}\n",
    "\n",
    "for params, lag_ranks in param_rankings.items():\n",
    "    \n",
    "    optimal_lag_order[proposed_folder][params.c] = np.argmin(lag_ranks, axis=1).astype(int)\n",
    "    optimal_lag_order[comparison_folder][params.c] = np.argmin(comparison_lag_ranks, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Granger Causality\n",
    "Now we have verified the lag order, lets check for granger causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder, timeseries_dict in results.items():\n",
    "    print(folder)\n",
    "    \n",
    "    for params, result in timeseries_dict.items():\n",
    "        \n",
    "        if params.c == 0 or params.c == 1:\n",
    "            continue\n",
    "\n",
    "        population_entropies = result[\"entropy\"]\n",
    "        p_values = []\n",
    "\n",
    "        for run_idx, population_entropy in enumerate(population_entropies):\n",
    "\n",
    "            observed_volatility = result[\"volatility\"][run_idx]\n",
    "            df = pd.DataFrame({\"vol\": list(observed_volatility), \"ent\": population_entropy})\n",
    "            df.index = pd.RangeIndex(start=0, stop=len(population_entropy))\n",
    "\n",
    "            model = VAR(df)\n",
    "            \n",
    "            lag_order = optimal_lag_order[folder][params.c][run_idx]\n",
    "            model_results = model.fit(lag_order)\n",
    "\n",
    "            # See if entropy granger-causes volatility\n",
    "            granger = model_results.test_causality(\"vol\", \"ent\", kind='f')\n",
    "            p_values.append(granger.pvalue)\n",
    "\n",
    "        #plt.hist(p_values, bins=10)\n",
    "        #plt.show()\n",
    "\n",
    "        # Combine p values\n",
    "        significance = hmp.hmp(p_values)\n",
    "        print(params, significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulse response analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irf_values(values, impulse, response, names):\n",
    "    \"\"\"\n",
    "    Reusable function to make flexible grid plots of impulse responses and\n",
    "    comulative effects\n",
    "    \"\"\"\n",
    "    # We only plot one, extract the indices for the impulse/response from names\n",
    "    _, _, to_plot = plotting._get_irf_plot_config(names, impulse, response)\n",
    "    \n",
    "    # Just the index of our impulse and response\n",
    "    (j, i, _, _) = to_plot[0]\n",
    "    \n",
    "    return values[:, i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSpline(effect):\n",
    "    \"\"\"\n",
    "        Use cubic BSpline to smooth the impulse responses\n",
    "    \"\"\"\n",
    "    T = range(len(effect))\n",
    "    xnew = np.linspace(0, len(T)-1, 1000) \n",
    "\n",
    "    spl = make_interp_spline(T, effect, k=3) # Cubic BSpline\n",
    "    smoothed = spl(xnew)\n",
    "    \n",
    "    return xnew, smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_smooth_response(effects, color):\n",
    "    q1_effect, median_effect, q3_effect = np.percentile(effects, q=[25,50, 75], axis=0)\n",
    "    \n",
    "    # All x's will be same\n",
    "    x, smoothed_q1 = BSpline(q1_effect)\n",
    "    x, smoothed_median = BSpline(median_effect)\n",
    "    x, smoothed_q3 = BSpline(q3_effect)\n",
    "\n",
    "    plt.plot(x, smoothed_median, c=color)\n",
    "    plt.fill_between(x, smoothed_q1, smoothed_q3, alpha=0.2, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_impulse_responses(results, folder):\n",
    "\n",
    "    param_results = results[folder]\n",
    "    param_effects = {}\n",
    "    \n",
    "    for params, result in param_results.items():\n",
    "        \n",
    "        if params.c == 0 or params.c == 1:\n",
    "            continue\n",
    "\n",
    "        population_entropies = result[\"entropy\"]\n",
    "        effects = []\n",
    "\n",
    "        for run_idx, population_entropy in enumerate(population_entropies):\n",
    "\n",
    "            observed_volatility = result[\"volatility\"][run_idx]\n",
    "\n",
    "            df = pd.DataFrame({\"vol\": list(observed_volatility), \"ent\": population_entropy})\n",
    "            df.index = pd.RangeIndex(start=0, stop=len(population_entropy))\n",
    "\n",
    "            model = VAR(df)\n",
    "            lag_order = optimal_lag_order[folder][params.c][run_idx]\n",
    "            model_results = model.fit(lag_order)\n",
    "            irf = model_results.irf(periods=20)\n",
    "\n",
    "            effect = irf_values(irf.irfs, impulse='ent', response='vol', names=irf.model.names)\n",
    "            effects.append(effect)\n",
    "            \n",
    "        param_effects[params] = np.asarray(effects)\n",
    "            \n",
    "    return param_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposed_responses = compute_impulse_responses(results, proposed_folder)\n",
    "comparison_responses = compute_impulse_responses(results, comparison_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params, effects in proposed_responses.items():\n",
    "    \n",
    "    comparison_effects = comparison_responses[params]\n",
    "    \n",
    "    plot_smooth_response(effects, color=\"purple\")\n",
    "    plot_smooth_response(comparison_effects, color=\"orange\")\n",
    "\n",
    "    plt.xticks(range(0, effects.shape[1], 5))\n",
    "    plt.savefig(f\"images/irf/{params.c}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
